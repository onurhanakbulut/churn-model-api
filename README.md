ğŸ§  Churn Model API (XGBoost Â· FastAPI)

**https://churn-dashboard-demo.streamlit.app**

A lightweight and production-ready REST API that serves an e-commerce churn prediction model trained with XGBoost.
It takes customer behavioral features and returns their churn probability â€” helping businesses identify at-risk customers.

ğŸš€ Features

âš¡ Fast inference powered by FastAPI + Uvicorn

âœ… Strict request validation via Pydantic

ğŸ§© Model path configurable with environment variable (MODEL_PATH)

ğŸ³ Containerized with Docker

ğŸŒ CORS-enabled â€” easily integrates with Streamlit dashboards

ğŸ“¦ Tech Stack

Python â€¢ FastAPI â€¢ XGBoost â€¢ scikit-learn â€¢ joblib â€¢ Pydantic â€¢ Docker

ğŸ”Œ API Overview
Health Check
GET /health
â†’ 200 OK
{
  "status": "ok"
}

Predict (Single Record)
POST /predict
Content-Type: application/json
Body:
{
  "Frequency": 12,
  "Monetary": 358.4,
  "CustomerLifetimeDays": 210
}
Response (200):
{
  'predicted_class': 1,
  'churn_probability': 0.78,
  'is_churn': Churned
}
---------

âš™ï¸ Quickstart
1ï¸âƒ£ Clone the repository
git clone https://github.com/onurhanakbulut/churn-model-api.git
cd churn-model-api

2ï¸âƒ£ Install dependencies
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt

3ï¸âƒ£ Add your trained model

Place your serialized model (e.g. joblib.dump) inside:

app/churn_xgb_model.pkl


Or specify a custom model path:

set MODEL_PATH=app/churn_xgb_model.pkl  # Windows
export MODEL_PATH=app/churn_xgb_model.pkl  # Linux/macOS

4ï¸âƒ£ Run locally
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload


Then visit:
ğŸ‘‰ http://localhost:8000/docs

ğŸ³ Docker Usage
Build image
docker build -t churn-model-api:latest .

Run container
docker run --rm -p 8000:8000 \
  -e MODEL_PATH=/app/app/churn_xgb_model.pkl \
  churn-model-api:latest

âš™ï¸ Environment Variables
Variable	Default	Description
MODEL_PATH	app/churn_xgb_model.pkl	Path to serialized .pkl model file
HOST	0.0.0.0	Bind host for Uvicorn
PORT	8000	Server port
LOG_LEVEL	info	Log level: critical/error/warning/info/debug
ğŸ§ª Example Requests

Using cURL

curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"Frequency": 12, "Monetary": 358.4, "CustomerLifetimeDays": 210}'


Using Python

import requests

payload = {"Frequency": 12, "Monetary": 358.4, "CustomerLifetimeDays": 210}
r = requests.post("http://localhost:8000/predict", json=payload)
print(r.json())  # â†’ {'churn_probability': 0.27}


ğŸ‘©â€ğŸ’» Author

Onurhan Akbulut
Data Science & Machine Learning Engineer
ğŸ“¬ onurhanakbulut
